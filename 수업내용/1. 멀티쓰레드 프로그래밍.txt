서버 프로그래밍은 식당 운영과 비슷하다.
식당의 직원은 자기 스스로는 움직일 수 없고, 영혼이 들어가야만 움직일 수 있다고 가정하는데
이 차이만 있다고 하자.

레스토랑 - 프로세스(프로그램)
직원 - 쓰레드
영혼 - CPU 코어

이다.

영혼이 아주 빠른 속도로 각 직원에게 들어가 직원이 일하도록 돕는다.
이 속도는 아주 빠르기 때문에, 각 직원이 멈추지 않고 모두 일하는 것처럼 보인다.

한 프로세스의 서로 다른 쓰레드는 Heap과 Data 영역을 공유하며, 각자의 Stack 영역을 갖는다.


쓰레드 관련 함수
- t.hardware_concurrency();
	. CPU 논리 코어 개수
- t.get_id();
	. 쓰레드마다 주어지는 고유 ID
- t.detach();
	. std::thread 객체에서 실제 쓰레드를 분리
- t.joinable();
	. join이 가능한지 확인 (실제로는 id가 0인지만 확인)
- t.join();
	. 해당 쓰레드가 종료될 때까지 대기


unique_lock
	. std::defer_lock을 통해 lock이 걸리는 시점을 제어할 수 있음.
lock_guard
	. unique_lock에 비해 조금이나마 가벼움
std::adopt_lock
	. lock_guard에 인자로 넘겨 이미 locking이 되어 있는 lock이라는 것을 lock_guard에 알린다.


데드락
- 두 개 이상의 작업이 서로가 점유하고 있는 자원을 무한히 기다리는 상황

데드락의 원인
- 다음 네 가지 조건이 만족되어야 한다.
	. 상호 배제 : 자원을 동시에 쓸 수 없으며 한번에 한 프로세스만이 해당 자원을 사용할 수 있다.
	. 점유 대기 : 한 자원을 사용하고 있으면서 다른 자원을 기다리는 상태
	. 선점 불가 : 한 프로세스가 선점하고 있는 자원을 다른 프로세스가 가져올 수 없음
	. 순환 대기 : 각자가 서로가 사용하는 자원을 얻으려고 대기하는 상황

해결 방법?
- 락을 클래스 등으로 래핑하여 락에 우선순위를 부여한다. (순환 대기 조건 해결)
- 완전한 해결은 힘들다. 데드락이 발생했을 때 처리는 다른 버그에 비해 상대적으로 쉽다.
- lock manager를 만들어 사이클이 발생했는지 확인한다.
	. 1번 lock을 잡은 상태에서 2번 lock을 잡을 수 있다면 1 - 2번 간 경로가 존재한다는 의미이다.
	. 2 - 3번 경로가 존재하고, 다시 3 - 1번 경로가 존재한다면 데드락의 발생 위험이 있다.
	. union find?


스핀락
- 나이브하게 스핀락을 구현해 보자
class SpinLock
{
public:
	void lock() {
		while (m_locked) {}
		m_locked = true;
	}
	void unlock() {
		m_locked = false;
	}

private:
	bool m_locked = false;
};
오동작한다.
우선 volatile이 없다. 따라서 m_locked의 최적화가 들어간다.
그러나 이 문제만은 아니다.

화장실에 들어가는 행동(m_lock이 false임을 확인), 자물쇠를 잠그는 행동(m_lock = true)은 한 번에 일어나야 한다.
거의 두 명의 사람이 동시에 화장실에 입장해 서로 자물쇠를 잠그려고 시도해서는 안된다.
그런데 이 행동이 원자적으로 일어나지 않는다.

CAS (Compare And Swap)
atomic_bool의 compare_exchange_strong 함수는 bool 타입 expected와 desired를 인자로 받아
객체와 expected가 같다면 객체를 desired로 바꾸고 true 리턴
객체와 expected가 다르다면 expected를 객체로 바꾸고 false를 리턴한다.
그리고 이 과정이 원자적으로 일어난다.

bool expected = false;
const bool desired = true;

while (m_locked.compare_exchange_strong(expected, desired) == false) 
{
	expected = false;
}
이와 같이 m_lock이 false임을 확인하고 이를 true로 바꾸는 행동을 원자적으로 실시할 수 있다.


Sleep
- 락을 얻을 수 없을 때 일단 자리로, 나중에 다시 시도

- this_thread::sleep_for();
- this_thread::yield();
	. 할당받은 time slice를 포기하고 다른 쓰레드에 넘긴다.


이벤트
- 직원(커널)이 통보해 줄 때까지 쓰레드는 잠든 상태가 된다.

- CreateEvent
	. MenualReset
	  true시 MenualReset(수동 리셋), false시 AutoReset(자동 리셋)


조건 변수(Condition Variable)
- 어떤 조건을 만족할 때까지 쓰레드를 재운다.
- 표준 mutex와 연동되어 동작 (그렇게 하지 않으려면 condition_variable_any 사용)
- 이벤트와 같은 커널 오브젝트가 아닌 User-Level Object
  즉 다른 프로그램끼리 동기화할 수 없고 동일한 프로그램 내에서만 동기화할 수 있음

- condition_variable::notify_one()
	. 조건이 거짓인 바람에 자고 있는 쓰레드들 중 하나를 깨워서 조건을 검사한다.
- condition_variable::notify_all()
	. 조건이 거짓인 바람에 자고 있는 쓰레드 모두를 깨워서 조건을 검사한다.
- condition_variable::wait()
	. unique_lock을 인자로 받아 lock을 걸 수 있으면 건다.
	  조건을 만족할 경우 빠져나가 코드를 진행한다.
	  만족하지 않을 경우 lock을 풀어 주고 다시 잠든다.


미래 객체(future)
- C++에서 비동기 작업을 위해 thread와 join을 사용했어야 했다.

- async
	. 원하는 함수를 비동기적으로 실행한다.
- promise
	. 결과물을 promise 객체를 통해 future로 받아준다.
- packaged_task
	. 원하는 함수의 실행 결과를 packaged_task 객체를 통해 future로 받아준다.


mutex, condition_variable까지 가지 않고 1회성 작업을 처리하는데 유용하다.



캐시
- CPU는 연산을 하고, 메모리에 사용할 자원이 올라가 있다.
  CPU와 메모리까지의 길이가 멀기 때문에 데이터를 전송하는 시간이 CPU의 연산에 걸리는 시간보다 압도적으로 길다
  CPU는 캐시라는 개념을 도입하여 메모리에서 데이터를 꺼내올 때 동일한, 혹은 인접한 데이터를 한번에
  메모리에서 캐시에 올리게 된다. CPU는 사용할 데이터가 캐시에 있을 때 메모리까지 가지 않고 캐시에서 데이터를 꺼내
  쓰게 된다.
- 시간적 지역성(Temporal Locality)
	. 방금 주문한 테이블에서 추가 주문이 나올 확률이 높다.
- 공간적 지역성(Spetial Locality)
	. 주문한 근처에 있는 사람이 추가 주문을 할 확률이 높다.


CPU 파이프라이닝
- 두 쓰레드에서 각각 x = 1; r1 = y; 와 y = 1; r2 = x를 동시에 실행한다고 가정하자.
  x == 0 and y == 0일 때 탈출한다고 가정하면, 프로그램이 순서대로 실행된다는 가정 하에
  탈출이 불가능해야 하지만 탈출하는 경우가 있다.
- 재배치 문제
	. 작업한 코드를 컴파일러가 곧이 곧대로 바꿔주지 않을 수 있다. 코드의 순서를 바꿨을 때 더 나은 결과가 나올 것
	  같다면 그렇게 한다. 이 때 멀티쓰레드에서 동작할 것이라고 고려하지 않는다.
	. 디스어셈블리를 열어 봤을 때 코드의 재배치는 되어 있지 않다. CPU에서도 코드의 위치를 바꿀 수 없다.
- 빨래를 해야 하는 상황이 있다고 가정하자. 빨래를 세탁기에 넣고 돌리고, 건조기에 넣고, 빨래를 개야 한다.
  여러 바구니의 빨래를 해야 한다고 가정한다면, 하나의 빨래가 전부 처리된 후 다른 빨래를 처리하는 것은 비효율적이다.
  하나의 빨래가 건조기에 돌아가는 동안 다른 빨래는 세탁기를 돌린다면(멀티쓰레드) 더 효율적으로 작업을 처리할 수 있다.
  또한 세탁이나 빨래 개기는 30분 걸리는데, 건조에 3시간이 걸린다면 컴파일러는 CPU의 파이프라인을 효율적으로 활용할 수 있도록
  명령을 재배치 하게 된다.
- 가시성 문제
	. CPU가 값을 읽을 때 항상 메모리에 읽는 것이 아니라 값이 캐시에 있다면 캐시에 있는 값을 읽는다.
	  그런데 코어마다 서로 다른 캐시를 가지고 있다.
	  즉 어떤 코어의 캐시에 x = 1을 기록했으나 다른 코어에서는 이를 관측할 수 없는 문제가 충분히 발생할 수 있다.
	. (C#에서는 volatile 키워드로 가시성 문제를 해결할 수 있다.)
- 어떤 변수가 1, 2, 3, 4의 순대로 변한다고 가정하자. 여러 쓰레드에서 이 변수를 읽는다면 1-2, 2-3-4, 1-3-4와 같이 관측될 수 있다.
  그런데 어떤 시점에 한 쓰레드에서 3이 관측되었는데, 그 이후의 시점에 다른 쓰레드에서 2가 관측될 수 있다. 이는 CPU의 각 코어가
  별도의 캐시를 가지고 있기 때문이다. 어떤 코어에서 변수를 수정한 후, 수정한 값을 자신의 캐시에만 기록해 둔다면 다른 코어에서
  이 변수가 변했는지 확인할 방법이 없다.
  디만, 어떤 쓰레드에서 3이 관측되었는데, 이후에 그 쓰레드에서 2가 관측되는 일은 절대 없음이 보장된다.


메모리 모델
- 경쟁 상태(Race Condition)
	. 여러 쓰레드가 동일한 메모리에 동시 접근. 그 중 하나 이상은 Write 연산
	. Undefined Behavior
	  - Lock을 이용한 상호 배타적(Mutual Exclusive) 접근
	  - Atomic(원자적) 연산을 이용
- Atomic 연산에 한해, 모든 쓰레드가 동일 객체에 대해서 동일한 수정 순서가 관측됨이 보장된다.
	. 동일 객체? : 변수가 여러 개일 때는 다른 수정 순서가 관측될 수 있다.
- is_lock_free()
	. 원자적으로 수정될 수 있는지 여부
- memory order
	. store, load를 할 때 어떤 정책으로 실시할 지 정해줄 수 있다.

- exchange
	. atomic_bool flag = false;
	  bool prev = flag;
	  flag = true;
	  위와 같은 코드는 문제가 있다.
	  이 때 다른 쓰레드가 flag를 수정한다면 prev에 유효하지 않은 값이 들어가게 된다.
	  따라서 prev에 저장하고 flag를 수정하는 행위가 원자적으로 일어나야 한다.
	  bool prev = flag.exchange(true);
	  위 코드는 prev에 이전 flag값을 대입하고 flag에는 인자를 대입하게 하는데
	  이 과정이 원자적으로 일어난다.
- compare_exchange_strong
	. expected와 desired를 인자로 받는다.
	  객체와 expected를 비교하여, 같으면 객체를 desired로 바꾸고 true 리턴.
	  다르면 expected를 객체로 바꾸고 false를 리턴한다.
	  이 과정이 원자적으로 일어난다.
- compare_exchange_weak
	. strong과 비슷하나. flag == expected일 때 다른 쓰레드의 interruption을 받아
	  중간에 실패할 수 있다. 이 경우 같음에도 false를 리턴하게 된다.
	  strong은 이러한 상황이 나오면 반복을 통해 나오지 않도록 한다.

메모리 모델 정책
1) Sequentially Consistent (seq_cst)
	. 가장 엄격 == 컴파일러 최적화 여지 적음 == 직관적
	. 가시성 문제 해결.
	. 코드 재배치 문제 해결.
2) Acquire Release (consume, acquire, release, acq_rel)
	. consume은 일단 잊자
	. 일반적으로 Producer(Writer) 입장에서 release, Consumer(Reader) 입장에서 acquire로 짝을 맞춘다.
	. release 명령 이전의 메모리 명령들이, 해당 명령 이후로 재배치 되는 것을 막는다.
	. 그리고 acquire로 같은 변수를 읽는 쓰레드가 있다면
	  release 이전의 명령들이 -> acquire 하는 순간에 관측 가능하다. (가시성 문제 해결)
3) Relaxed (relaxed)
	. 자유롭다 == 컴파일러 최적화 여지 많음 == 비직관적)
	. 가시성 문제 해결 안 됨
	. 코드 재배치 가능
	. 동일 객체에 대한 동일 관측 순서만 보장

인텔, AMD의 경우 애당초 순차적 일관성을 보장한다.
seq_cst를 써도 별다른 부하가 없다.
그러나 ARM의 경우 꽤 유의미한 차이가 있다.

반드시 atomic을 사용해야 하나?
memory barrier라는 기능을 CPU에서 지원한다.
std::atomic_thread_fence


Thread Local Storage(TLS)
쓰레드마다 독립적으로 가지고 있는 공간.
힙, 데이터 영역과 같이 모든 쓰레드가 공유하는 영역에 접근할 때, 경합이 너무 심해지게 되면
어떤 쓰레드는 일을 못하고 대기하게 된다.
그런데 TLS에 데이터를 가져와 처리하게 되면 효율적으로 접근할 수 있게 된다.
멀티쓰레드에서 가장 중요한 것 -> 쓰레드에 일감을 적절하게 배분하는 것



Lock-Free Stack